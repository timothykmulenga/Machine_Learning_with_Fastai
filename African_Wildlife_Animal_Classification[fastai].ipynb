{"cells":[{"metadata":{},"cell_type":"markdown","source":"# This notebook classifies 4 african wildlife using the fastai library.\n\n**Buffalos | Elephants | Rhino | Zebra**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The fastai library is based on research into deep learning best practices undertaken at fast.ai, and includes \"out of the box\" support for vision, text, tabular, and collab (collaborative filtering) models. This library allows high acurracy to be achieved with little training data. In this notebook we will be using the computer vision library from fastai to train on small data set. \n\nThe fastai library enables a friendly entry into Machine Learning for people coming from different domains to help apply ML to the fields with ease. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Acknowledgements\n\nFastai contributers","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Setup**","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# first we import the libraries\n\nfrom fastai.vision import * \nfrom fastai import *\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Load data**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"path = \"../input/african-wildlife\" # path to data set in kaggle\n\nnp.random.seed(42)\ndata = ImageDataBunch.from_folder(path, train=\".\", valid_pct=0.2,\n        ds_tfms=get_transforms(), size=224, num_workers=4).normalize(imagenet_stats)\n#imagedatabunch wraps the dataset and transforms is into the require format for training our model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#list classes\ndata.classes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data Visualisation**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.show_batch(rows=4, figsize=(7,8))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Define the model**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#the model uses tranfer learning using the resnet34\nlearn = cnn_learner(data, models.resnet34, metrics=accuracy, callback_fns=ShowGraph)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Train the model**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(5) # we set the model to run for 5 epochs","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* We get an accuracy of** 97.00%** with just few training and under a short period of time and a few lines of code","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# we can also plot a confusion matrix to analyse how are model performed","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"interp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}